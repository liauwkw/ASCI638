<h1> Human Factors </h1>
Traditionally, UAS development focused on iterating viable products with little focus on transferability and integration into the civil environment (Federal Aviation Administration (FAA), 2016). UAS human factors present unique, state-of-the-art, or state-of-research problems due to their existence as manoeuvrable remote systems. State-of-the-art problems involve the use and pairing of nascent technologies while state-of-research problems are known research areas that have seen little progress due to limitations of public planning, such as rigid or slow development timelines (FAA, 2016). Reviewing the 2016 FAA Human Factors Panel nearly five years on, the three human factors issues that continue to have the greatest effect on safe UAS operations are (1) distraction management, (2) mode confusion and (3) operating requirements and procedures.

<h2>Distraction Management</h2>
The introduction of UAS into the National Airspace System (NAS) juxtaposed potentially haphazard UAS systems with a legacy and procedural system of systems. From a systems integration perspective, UAS could be either integrated, segregated, or isolated with or from the legacy NAS stakeholders, systems, and procedures (FAA, 2016). Further, experts of the 2016 panel suggested that the workload and procedures of Air Traffic Controllers should not be increased (FAA, 2016). These considerations were materialized in a concept of operations (ConOps) that separated Unmanned Aircraft System Traffic Management (UTM) from Air Traffic Management (ATM) (FAA, 2020). The effectiveness of the ConOps remains to be seen, as COVID-19 presented compelling scenarios where UAS operations substitute or complement legacy operations, such as delivering COVID diagnostic kits (Njbiz & Sep, 2020). COVID-19 resurfaced opportunities to marry manned aviation with UAS operations, most notably in terms of job opportunities when flights are halted, if pilots possessed the skills to transition seamlessly to UAS operations. At this juncture, an improvement would be to further model helpful and harmful scenarios that match the present operational environment.
  
<h2>Mode Confusion</h2>
Mode confusion refers to a misdiagnosis of automation as well as the resultant operating characteristics of the UAS, leading to loss of situation awareness and erroneous flight control inputs (Miller, Barber, Carlson, Lempia, & Tribble, 2002). Notable flight modes include attitude limitation (or stabilization),  hover, autonomous flight, return to home and immediate landing (Jenkins, 2018). While UAS training curriculums include a familiarization of such modes, they could be deprecated as nascent developments introduced complex methods alongside known ones that may be more effective, such as indoor navigation using a 3D spatial template matching method enabled by computer vision, a form of artificial intelligence (AI) (Jin, Ko, & Lee, 2018). Further, these developments made no account of the risks when these UAS operate outdoors or in unexpected environments for additional tasks or recovery. Separately for autonomous landing, researchers studied the use of AI with visible-light-camera sensors intended as a redundancy of the Global Positioning System (GPS), posing a different operating concept (Nguyen et al., 2018). Recently, researchers at Google suggested that “underspecification” could result in the failure of AI techniques due to inadequate testing such as limited operating conditions (Heaven, 2020). 
With these complexities introduced, drone operators could conduct additional test flights in their desired deployment locations, even though they face an enigma of contingencies or failures to simulate for AI. Further, while a manned pilot could continue to “fly” the aircraft in contingencies, the UAS operator is reduced to guessing AI behavior that may be primary controls or may override operator input. To mitigate unpredictable failures, drone manufacturers and operators could introduce AI as features that can be disabled, and practise resilient override and shutdown procedures. 

<h2>Operating Requirements and Procedures</h2>
Fundamentally, operating requirements and procedures differ between UAS operators and manned aircraft pilots in terms of their use of sensing technologies, manoeuvrability, communications and expectations (FAA, 2016). It is also worth noting that contradictions exist between operating requirements and innovation, such First-Person View (FPV) being impeded by line-of-sight regulations seeking to bridge the distance (Calandrillo, Oh, & Webb, 2020, p. 191). The FAA circumscribed this roadblock by requiring FPV users to be accompanied by a spotter without binoculars (FAA, 2020). Inevitably, it introduced additional operating costs while folding-in the mismatch. Even if FPVs could be improved to display position awareness and localization functions, a concern for the potential outage of the onboard FPV camera suggests the permanence of the spotter. 

<h2>Conclusion</h2>
	In summary, distraction management, mode confusion as well as operating requirements and procedures pose significant and perpetual human factors challenges to safe UAS operations due to the unique nature of UAS being evergreening remote technologies. While these human factors introduce significant risks, possible mitigation strategies include further scenario modelling, user testing, options to override AI features and introducing spotters. Overall, it is crucial to note that technologies are not developed in vacuum and are laden with legislative, practical, and operational concerns.

<h4>@liauwkw, 2020</h4>

<h2>References</h2>
Calandrillo, S., Oh, J., & Webb, A. (2020). Deadly Drones: Why FAA Regulations Miss the Mark on Drone Safety. Stanford Technology Law Review, 23. 

Federal Aviation Administration. (2020). Fact Sheet – Small Unmanned Aircraft Systems (UAS) Regulations (Part 107). (Part 107). 

Federal Aviation Administration (FAA). (2016). FAA TV: Human Factors (HF), Panel 1: Overview. Retrieved from https://www.faa.gov/tv/?mediaId=1462

Federal Aviation Administration (FAA). (2020). Unmanned Aircraft System (UAS) Traffic Management (UTM): Concept of Operations v2.0. Retrieved from https://www.faa.gov/uas/research_development/traffic_management/media/UTM_ConOps_v2.pdf

Heaven, W. D. (2020). The way we train AI is fundamentally flawed. Retrieved November 21, 2020, from MIT Technology Review website: https://www.technologyreview.com/2020/11/18/1012234/training-machine-learning-broken-real-world-heath-nlp-computer-vision/

Jenkins, K. (2018). Chapter 3: Common Flight Modes. In The Droner’s Manual: A Guide to the Responsible Operation of Small Unmanned Aircraft (pp. 90–91). Retrieved from https://ebookcentral-proquest-com.ezproxy.libproxy.db.erau.edu/lib/erau/detail.action?docID=5275564

Jin, Y. H., Ko, K. W., & Lee, W. H. (2018). An indoor location-based positioning system using stereo vision with the drone camera. Mobile Information Systems, 2018. https://doi.org/10.1155/2018/5160543

Miller, S. P., Barber, S., Carlson, T. M., Lempia, D. L., & Tribble, A. C. (2002). A methodology for improving mode awareness in flight guidance design. Proceedings. The 21st Digital Avionics Systems Conference, 2, 7D1-7D1. https://doi.org/10.1109/DASC.2002.1052928

Nguyen, P. H., Arsalan, M., Koo, J. H., Naqvi, R. A., Truong, N. Q., & Park, K. R. (2018). LightdenseYOLO: A fast and accurate marker tracker for autonomous UAV landing by visible light camera sensor on drone. Sensors (Switzerland), 18(6). https://doi.org/10.3390/s18061703

Njbiz, L., & Sep, N. B. (2020). Walmart , Quest Diagnostics partner for at-home COVID kit delivery by drone. 1–2.

